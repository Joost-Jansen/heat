{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch\n", "import torch.nn as nn\n", "from torch.utils.data import DataLoader\n", "from datasets.outdoor_buildings import OutdoorBuildingDataset\n", "from datasets.s3d_floorplans import S3DFloorplanDataset\n", "from datasets.data_utils import collate_fn, get_pixel_features\n", "from models.resnet import ResNetBackbone\n", "from models.corner_models import HeatCorner\n", "from models.edge_models import HeatEdge\n", "from models.corner_to_edge import get_infer_edge_pairs\n", "from utils.geometry_utils import corner_eval\n", "import numpy as np\n", "import cv2\n", "import os\n", "import scipy.ndimage.filters as filters\n", "import matplotlib.pyplot as plt\n", "from metrics.get_metric import compute_metrics, get_recall_and_precision\n", "import skimage\n", "import argparse"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def visualize_cond_generation(positive_pixels, confs, image, save_path, gt_corners=None, prec=None, recall=None,\n", "                              image_masks=None, edges=None, edge_confs=None):\n", "    image = image.copy()  # get a new copy of the original image\n", "    if confs is not None:\n", "        viz_confs = confs\n", "    if edges is not None:\n", "        preds = positive_pixels.astype(int)\n", "        c_degrees = dict()\n", "        for edge_i, edge_pair in enumerate(edges):\n", "            conf = (edge_confs[edge_i] * 2) - 1\n", "            cv2.line(image, tuple(preds[edge_pair[0]]), tuple(preds[edge_pair[1]]), (255 * conf, 255 * conf, 0), 2)\n", "            c_degrees[edge_pair[0]] = c_degrees.setdefault(edge_pair[0], 0) + 1\n", "            c_degrees[edge_pair[1]] = c_degrees.setdefault(edge_pair[1], 0) + 1\n", "    for idx, c in enumerate(positive_pixels):\n", "        if edges is not None and idx not in c_degrees:\n", "            continue\n", "        if confs is None:\n", "            cv2.circle(image, (int(c[0]), int(c[1])), 3, (0, 0, 255), -1)\n", "        else:\n", "            cv2.circle(image, (int(c[0]), int(c[1])), 3, (0, 0, 255 * viz_confs[idx]), -1)\n", "        # if edges is not None:\n", "        #    cv2.putText(image, '{}'.format(c_degrees[idx]), (int(c[0]), int(c[1] - 5)), cv2.FONT_HERSHEY_SIMPLEX,\n", "        #                0.5, (255, 0, 0), 1, cv2.LINE_AA)\n", "    if gt_corners is not None:\n", "        for c in gt_corners:\n", "            cv2.circle(image, (int(c[0]), int(c[1])), 3, (0, 255, 0), -1)\n", "    if image_masks is not None:\n", "        mask_ids = np.where(image_masks == 1)[0]\n", "        for mask_id in mask_ids:\n", "            y_idx = mask_id // 64\n", "            x_idx = (mask_id - y_idx * 64)\n", "            x_coord = x_idx * 4\n", "            y_coord = y_idx * 4\n", "            cv2.rectangle(image, (x_coord, y_coord), (x_coord + 3, y_coord + 3), (127, 127, 0), thickness=-1)\n\n", "    # if confs is not None:\n", "    #    cv2.putText(image, 'max conf: {:.3f}'.format(confs.max()), (20, 20), cv2.FONT_HERSHEY_SIMPLEX,\n", "    #                0.5, (255, 255, 0), 1, cv2.LINE_AA)\n", "    if prec is not None:\n", "        if isinstance(prec, tuple):\n", "            cv2.putText(image, 'edge p={:.2f}, edge r={:.2f}'.format(prec[0], recall[0]), (20, 20),\n", "                        cv2.FONT_HERSHEY_SIMPLEX,\n", "                        0.5, (255, 255, 0), 1, cv2.LINE_AA)\n", "            cv2.putText(image, 'region p={:.2f}, region r={:.2f}'.format(prec[1], recall[1]), (20, 40),\n", "                        cv2.FONT_HERSHEY_SIMPLEX,\n", "                        0.5, (255, 255, 0), 1, cv2.LINE_AA)\n", "        else:\n", "            cv2.putText(image, 'prec={:.2f}, recall={:.2f}'.format(prec, recall), (20, 20), cv2.FONT_HERSHEY_SIMPLEX,\n", "                        0.5, (255, 255, 0), 1, cv2.LINE_AA)\n", "    cv2.imwrite(save_path, image)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def corner_nms(preds, confs, image_size):\n", "    data = np.zeros([image_size, image_size])\n", "    neighborhood_size = 5\n", "    threshold = 0\n", "    for i in range(len(preds)):\n", "        data[preds[i, 1], preds[i, 0]] = confs[i]\n", "    data_max = filters.maximum_filter(data, neighborhood_size)\n", "    maxima = (data == data_max)\n", "    data_min = filters.minimum_filter(data, neighborhood_size)\n", "    diff = ((data_max - data_min) > threshold)\n", "    maxima[diff == 0] = 0\n", "    results = np.where(maxima > 0)\n", "    filtered_preds = np.stack([results[1], results[0]], axis=-1)\n", "    new_confs = list()\n", "    for i, pred in enumerate(filtered_preds):\n", "        new_confs.append(data[pred[1], pred[0]])\n", "    new_confs = np.array(new_confs)\n", "    return filtered_preds, new_confs"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main(dataset, ckpt_path, image_size, viz_base, save_base, infer_times):\n", "    ckpt = torch.load(ckpt_path)\n", "    print('Load from ckpts of epoch {}'.format(ckpt['epoch']))\n", "    ckpt_args = ckpt['args']\n", "    if dataset == 'outdoor':\n", "        data_path = './data/outdoor/cities_dataset'\n", "        det_path = './data/outdoor/det_final'\n", "        test_dataset = OutdoorBuildingDataset(data_path, det_path, phase='test', image_size=image_size, rand_aug=False,\n", "                                              inference=True)\n", "    elif dataset == 's3d_floorplan':\n", "        data_path = './data/s3d_floorplan'\n", "        test_dataset = S3DFloorplanDataset(data_path, phase='test', rand_aug=False, inference=True)\n", "    else:\n", "        raise ValueError('Unknown dataset type: {}'.format(dataset))\n", "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0,\n", "                                 collate_fn=collate_fn)\n", "    backbone = ResNetBackbone()\n", "    strides = backbone.strides\n", "    num_channels = backbone.num_channels\n", "    backbone = nn.DataParallel(backbone)\n", "    backbone = backbone.cuda()\n", "    backbone.eval()\n", "    corner_model = HeatCorner(input_dim=128, hidden_dim=256, num_feature_levels=4, backbone_strides=strides,\n", "                              backbone_num_channels=num_channels)\n", "    corner_model = nn.DataParallel(corner_model)\n", "    corner_model = corner_model.cuda()\n", "    corner_model.eval()\n", "    edge_model = HeatEdge(input_dim=128, hidden_dim=256, num_feature_levels=4, backbone_strides=strides,\n", "                          backbone_num_channels=num_channels)\n", "    edge_model = nn.DataParallel(edge_model)\n", "    edge_model = edge_model.cuda()\n", "    edge_model.eval()\n", "    backbone.load_state_dict(ckpt['backbone'])\n", "    corner_model.load_state_dict(ckpt['corner_model'])\n", "    edge_model.load_state_dict(ckpt['edge_model'])\n", "    print('Loaded saved model from {}'.format(ckpt_path))\n", "    if not os.path.exists(viz_base):\n", "        os.makedirs(viz_base)\n", "    if not os.path.exists(save_base):\n", "        os.makedirs(save_base)\n", "    all_prec = list()\n", "    all_recall = list()\n", "    corner_tp = 0.0\n", "    corner_fp = 0.0\n", "    corner_length = 0.0\n", "    edge_tp = 0.0\n", "    edge_fp = 0.0\n", "    edge_length = 0.0\n", "    region_tp = 0.0\n", "    region_fp = 0.0\n", "    region_length = 0.0\n\n", "    # get the positional encodings for all pixels\n", "    pixels, pixel_features = get_pixel_features(image_size=image_size)\n", "    for data_i, data in enumerate(test_dataloader):\n", "        image = data['img'].cuda()\n", "        img_path = data['img_path'][0]\n", "        annot_path = data['annot_path'][0]\n", "        annot = np.load(annot_path, allow_pickle=True, encoding='latin1').tolist()\n", "        with torch.no_grad():\n", "            pred_corners, pred_confs, pos_edges, edge_confs, c_outputs_np = get_results(image, annot, backbone,\n", "                                                                                        corner_model,\n", "                                                                                        edge_model,\n", "                                                                                        pixels, pixel_features,\n", "                                                                                        ckpt_args, infer_times,\n", "                                                                                        corner_thresh=0.01,\n", "                                                                                        image_size=image_size)\n\n", "        # viz_image = cv2.imread(img_path)\n", "        positive_pixels = np.array(list(annot.keys())).round()\n", "        viz_image = data['raw_img'][0].cpu().numpy().transpose(1, 2, 0)\n", "        viz_image = (viz_image * 255).astype(np.uint8)\n\n", "        # visualize G.T.\n", "        gt_path = os.path.join(viz_base, '{}_gt.png'.format(data_i))\n", "        visualize_cond_generation(positive_pixels, None, viz_image, gt_path, gt_corners=None, image_masks=None)\n", "        if len(pred_corners) > 0:\n", "            prec, recall = corner_eval(positive_pixels, pred_corners)\n", "        else:\n", "            prec = recall = 0\n", "        all_prec.append(prec)\n", "        all_recall.append(recall)\n", "        if pred_confs.shape[0] == 0:\n", "            pred_confs = None\n", "        if image_size != 256:\n", "            pred_corners_viz = pred_corners * (image_size / 256)\n", "        else:\n", "            pred_corners_viz = pred_corners\n", "        recon_path = os.path.join(viz_base, '{}_pred_corner.png'.format(data_i))\n", "        visualize_cond_generation(pred_corners_viz, pred_confs, viz_image, recon_path, gt_corners=None, prec=prec,\n", "                                  recall=recall)\n", "        pred_corners, pred_confs, pos_edges = postprocess_preds(pred_corners, pred_confs, pos_edges)\n", "        pred_data = {\n", "            'corners': pred_corners,\n", "            'edges': pos_edges,\n", "        }\n", "        if dataset == 's3d_floorplan':\n", "            save_filename = os.path.basename(annot_path)\n", "            save_npy_path = os.path.join(save_base, save_filename)\n", "            np.save(save_npy_path, pred_data)\n", "        else:\n", "            save_results = {\n", "                'corners': pred_corners,\n", "                'edges': pos_edges,\n", "                'image_path': img_path,\n", "            }\n", "            save_path = os.path.join(save_base, '{}_results.npy'.format(data_i))\n", "            np.save(save_path, save_results)\n", "        gt_data = convert_annot(annot)\n", "        score = compute_metrics(gt_data, pred_data)\n", "        edge_recall, edge_prec = get_recall_and_precision(score['edge_tp'], score['edge_fp'], score['edge_length'])\n", "        region_recall, region_prec = get_recall_and_precision(score['region_tp'], score['region_fp'],\n", "                                                              score['region_length'])\n", "        er_recall = (edge_recall, region_recall)\n", "        er_prec = (edge_prec, region_prec)\n", "        if image_size != 256:\n", "            pred_corners_viz = pred_corners * (image_size / 256)\n", "        else:\n", "            pred_corners_viz = pred_corners\n", "        recon_path = os.path.join(viz_base, '{}_pred_edge.png'.format(data_i))\n", "        visualize_cond_generation(pred_corners_viz, pred_confs, viz_image, recon_path, gt_corners=None, prec=er_prec,\n", "                                  recall=er_recall, edges=pos_edges, edge_confs=edge_confs)\n", "        corner_tp += score['corner_tp']\n", "        corner_fp += score['corner_fp']\n", "        corner_length += score['corner_length']\n", "        edge_tp += score['edge_tp']\n", "        edge_fp += score['edge_fp']\n", "        edge_length += score['edge_length']\n", "        region_tp += score['region_tp']\n", "        region_fp += score['region_fp']\n", "        region_length += score['region_length']\n", "        print('Finish inference for sample No.{}'.format(data_i))\n", "    avg_prec = np.array(all_prec).mean()\n", "    avg_recall = np.array(all_recall).mean()\n", "    recall, precision = get_recall_and_precision(corner_tp, corner_fp, corner_length)\n", "    f_score = 2.0 * precision * recall / (recall + precision + 1e-8)\n", "    print('corners - precision: %.3f recall: %.3f f_score: %.3f' % (precision, recall, f_score))\n\n", "    # edge\n", "    recall, precision = get_recall_and_precision(edge_tp, edge_fp, edge_length)\n", "    f_score = 2.0 * precision * recall / (recall + precision + 1e-8)\n", "    print('edges - precision: %.3f recall: %.3f f_score: %.3f' % (precision, recall, f_score))\n\n", "    # region\n", "    recall, precision = get_recall_and_precision(region_tp, region_fp, region_length)\n", "    f_score = 2.0 * precision * recall / (recall + precision + 1e-8)\n", "    print('regions - precision: %.3f recall: %.3f f_score: %.3f' % (precision, recall, f_score))\n", "    print('Avg prec: {}, Avg recall: {}'.format(avg_prec, avg_recall))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_results(image, annot, backbone, corner_model, edge_model, pixels, pixel_features,\n", "                args, infer_times, corner_thresh=0.5, image_size=256):\n", "    image_feats, feat_mask, all_image_feats = backbone(image)\n", "    pixel_features = pixel_features.unsqueeze(0).repeat(image.shape[0], 1, 1, 1)\n", "    preds_s1 = corner_model(image_feats, feat_mask, pixel_features, pixels, all_image_feats)\n", "    c_outputs = preds_s1\n", "    # get predicted corners\n", "    c_outputs_np = c_outputs[0].detach().cpu().numpy()\n", "    pos_indices = np.where(c_outputs_np >= corner_thresh)\n", "    pred_corners = pixels[pos_indices]\n", "    pred_confs = c_outputs_np[pos_indices]\n", "    pred_corners, pred_confs = corner_nms(pred_corners, pred_confs, image_size=c_outputs.shape[1])\n", "    pred_corners, pred_confs, edge_coords, edge_mask, edge_ids = get_infer_edge_pairs(pred_corners, pred_confs)\n", "    corner_nums = torch.tensor([len(pred_corners)]).to(image.device)\n", "    max_candidates = torch.stack([corner_nums.max() * args.corner_to_edge_multiplier] * len(corner_nums), dim=0)\n", "    all_pos_ids = set()\n", "    all_edge_confs = dict()\n", "    for tt in range(infer_times):\n", "        if tt == 0:\n", "            gt_values = torch.zeros_like(edge_mask).long()\n", "            gt_values[:, :] = 2\n\n", "        # run the edge model\n", "        s1_logits, s2_logits_hb, s2_logits_rel, selected_ids, s2_mask, s2_gt_values = edge_model(image_feats, feat_mask,\n", "                                                                                                 pixel_features,\n", "                                                                                                 edge_coords, edge_mask,\n", "                                                                                                 gt_values, corner_nums,\n", "                                                                                                 max_candidates,\n", "                                                                                                 True)\n", "        # do_inference=True)\n", "        num_total = s1_logits.shape[2]\n", "        num_selected = selected_ids.shape[1]\n", "        num_filtered = num_total - num_selected\n", "        s1_preds = s1_logits.squeeze().softmax(0)\n", "        s2_preds_rel = s2_logits_rel.squeeze().softmax(0)\n", "        s2_preds_hb = s2_logits_hb.squeeze().softmax(0)\n", "        s1_preds_np = s1_preds[1, :].detach().cpu().numpy()\n", "        s2_preds_rel_np = s2_preds_rel[1, :].detach().cpu().numpy()\n", "        s2_preds_hb_np = s2_preds_hb[1, :].detach().cpu().numpy()\n", "        selected_ids = selected_ids.squeeze().detach().cpu().numpy()\n", "        if tt != infer_times - 1:\n", "            s2_preds_np = s2_preds_hb_np\n", "            pos_edge_ids = np.where(s2_preds_np >= 0.9)\n", "            neg_edge_ids = np.where(s2_preds_np <= 0.01)\n", "            for pos_id in pos_edge_ids[0]:\n", "                actual_id = selected_ids[pos_id]\n", "                if gt_values[0, actual_id] != 2:\n", "                    continue\n", "                all_pos_ids.add(actual_id)\n", "                all_edge_confs[actual_id] = s2_preds_np[pos_id]\n", "                gt_values[0, actual_id] = 1\n", "            for neg_id in neg_edge_ids[0]:\n", "                actual_id = selected_ids[neg_id]\n", "                if gt_values[0, actual_id] != 2:\n", "                    continue\n", "                gt_values[0, actual_id] = 0\n", "            num_to_pred = (gt_values == 2).sum()\n", "            if num_to_pred <= num_filtered:\n", "                break\n", "        else:\n", "            s2_preds_np = s2_preds_hb_np\n", "            pos_edge_ids = np.where(s2_preds_np >= 0.5)\n", "            for pos_id in pos_edge_ids[0]:\n", "                actual_id = selected_ids[pos_id]\n", "                if s2_mask[0][pos_id] is True or gt_values[0, actual_id] != 2:\n", "                    continue\n", "                all_pos_ids.add(actual_id)\n", "                all_edge_confs[actual_id] = s2_preds_np[pos_id]\n\n", "    # print('Inference time {}'.format(tt+1))\n", "    pos_edge_ids = list(all_pos_ids)\n", "    edge_confs = [all_edge_confs[idx] for idx in pos_edge_ids]\n", "    pos_edges = edge_ids[pos_edge_ids].cpu().numpy()\n", "    edge_confs = np.array(edge_confs)\n", "    if image_size != 256:\n", "        pred_corners = pred_corners / (image_size / 256)\n", "    return pred_corners, pred_confs, pos_edges, edge_confs, c_outputs_np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def postprocess_preds(corners, confs, edges):\n", "    corner_degrees = dict()\n", "    for edge_i, edge_pair in enumerate(edges):\n", "        corner_degrees[edge_pair[0]] = corner_degrees.setdefault(edge_pair[0], 0) + 1\n", "        corner_degrees[edge_pair[1]] = corner_degrees.setdefault(edge_pair[1], 0) + 1\n", "    good_ids = [i for i in range(len(corners)) if i in corner_degrees]\n", "    if len(good_ids) == len(corners):\n", "        return corners, confs, edges\n", "    else:\n", "        good_corners = corners[good_ids]\n", "        good_confs = confs[good_ids]\n", "        id_mapping = {value: idx for idx, value in enumerate(good_ids)}\n", "        new_edges = list()\n", "        for edge_pair in edges:\n", "            new_pair = (id_mapping[edge_pair[0]], id_mapping[edge_pair[1]])\n", "            new_edges.append(new_pair)\n", "        new_edges = np.array(new_edges)\n", "        return good_corners, good_confs, new_edges"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def process_image(img):\n", "    mean = [0.485, 0.456, 0.406]\n", "    std = [0.229, 0.224, 0.225]\n", "    img = skimage.img_as_float(img)\n", "    img = img.transpose((2, 0, 1))\n", "    img = (img - np.array(mean)[:, np.newaxis, np.newaxis]) / np.array(std)[:, np.newaxis, np.newaxis]\n", "    img = torch.Tensor(img).cuda()\n", "    img = img.unsqueeze(0)\n", "    return img"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def plot_heatmap(results, filename):\n", "    # generate 2 2d grids for the x & y bounds\n", "    # import pdb; pdb.set_trace()\n", "    y, x = np.meshgrid(np.linspace(0, 255, 256), np.linspace(0, 255, 256))\n", "    z = results[::-1, :]\n", "    # x and y are bounds, so z should be the value *inside* those bounds.\n", "    # Therefore, remove the last value from the z array.\n", "    z = z[:-1, :-1]\n", "    fig, ax = plt.subplots()\n", "    c = ax.pcolormesh(y, x, z, cmap='RdBu', vmin=0, vmax=1)\n", "    # set the limits of the plot to the limits of the data\n", "    ax.axis([x.min(), x.max(), y.min(), y.max()])\n", "    fig.colorbar(c, ax=ax)\n", "    fig.savefig(filename)\n", "    plt.close()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def convert_annot(annot):\n", "    corners = np.array(list(annot.keys()))\n", "    corners_mapping = {tuple(c): idx for idx, c in enumerate(corners)}\n", "    edges = set()\n", "    for corner, connections in annot.items():\n", "        idx_c = corners_mapping[tuple(corner)]\n", "        for other_c in connections:\n", "            idx_other_c = corners_mapping[tuple(other_c)]\n", "            if (idx_c, idx_other_c) not in edges and (idx_other_c, idx_c) not in edges:\n", "                edges.add((idx_c, idx_other_c))\n", "    edges = np.array(list(edges))\n", "    gt_data = {\n", "        'corners': corners,\n", "        'edges': edges\n", "    }\n", "    return gt_data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def get_args_parser():\n", "    parser = argparse.ArgumentParser('Holistic edge attention transformer', add_help=False)\n", "    parser.add_argument('--dataset', default='outdoor',\n", "                        help='the dataset for experiments, outdoor/s3d_floorplan')\n", "    parser.add_argument('--checkpoint_path', default='',\n", "                        help='path to the checkpoints of the model')\n", "    parser.add_argument('--image_size', default=256, type=int)\n", "    parser.add_argument('--viz_base', default='./results/viz',\n", "                        help='path to save the intermediate visualizations')\n", "    parser.add_argument('--save_base', default='./results/npy',\n", "                        help='path to save the prediction results in npy files')\n", "    parser.add_argument('--infer_times', default=3, type=int)\n", "    return parser"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    parser = argparse.ArgumentParser('HEAT inference', parents=[get_args_parser()])\n", "    args = parser.parse_args()\n", "    main(args.dataset, args.checkpoint_path, args.image_size, args.viz_base, args.save_base,\n", "         infer_times=args.infer_times)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}